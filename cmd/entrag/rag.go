package main

import (
	"bufio"
	"bytes"
	"context"
	"crypto/md5"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"io"
	"io/fs"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"entgo.io/ent/dialect/sql"
	"github.com/charmbracelet/glamour"
	"github.com/pgvector/pgvector-go"
	"github.com/pkoukk/tiktoken-go"
	"github.com/rotemtam/entrag/ent"
	"github.com/rotemtam/entrag/ent/chunk"

	_ "github.com/lib/pq"
)

// ç¼“å­˜ç»“æ„
type EmbeddingCache struct {
	cache    map[string][]float32
	mutex    sync.RWMutex
	cacheDir string
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜ç»“æ„
type QACache struct {
	cache    map[string]string
	mutex    sync.RWMutex
	cacheDir string
}

var embeddingCache = &EmbeddingCache{
	cache:    make(map[string][]float32),
	cacheDir: ".entrag_cache",
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜å®ä¾‹
var qaCache = &QACache{
	cache:    make(map[string]string),
	cacheDir: ".entrag_cache",
}

// åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
func (c *EmbeddingCache) Init() error {
	// åˆ›å»ºç¼“å­˜ç›®å½•
	if err := os.MkdirAll(c.cacheDir, 0755); err != nil {
		return fmt.Errorf("failed to create cache directory: %v", err)
	}

	// åŠ è½½å·²æœ‰çš„ç¼“å­˜
	return c.loadFromDisk()
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜åˆå§‹åŒ–
func (c *QACache) Init() error {
	// åˆ›å»ºç¼“å­˜ç›®å½•
	if err := os.MkdirAll(c.cacheDir, 0755); err != nil {
		return fmt.Errorf("failed to create cache directory: %v", err)
	}

	// åŠ è½½å·²æœ‰çš„ç¼“å­˜
	return c.loadFromDisk()
}

// ä»ç£ç›˜åŠ è½½ç¼“å­˜
func (c *EmbeddingCache) loadFromDisk() error {
	c.mutex.Lock()
	defer c.mutex.Unlock()

	cacheFile := filepath.Join(c.cacheDir, "embeddings.json")
	if _, err := os.Stat(cacheFile); os.IsNotExist(err) {
		return nil // ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£å¸¸æƒ…å†µ
	}

	data, err := os.ReadFile(cacheFile)
	if err != nil {
		return fmt.Errorf("failed to read cache file: %v", err)
	}

	var diskCache map[string][]float32
	if err := json.Unmarshal(data, &diskCache); err != nil {
		return fmt.Errorf("failed to unmarshal cache data: %v", err)
	}

	c.cache = diskCache
	return nil
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜ä»ç£ç›˜åŠ è½½
func (c *QACache) loadFromDisk() error {
	c.mutex.Lock()
	defer c.mutex.Unlock()

	cacheFile := filepath.Join(c.cacheDir, "qa_cache.json")
	if _, err := os.Stat(cacheFile); os.IsNotExist(err) {
		return nil // ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ­£å¸¸æƒ…å†µ
	}

	data, err := os.ReadFile(cacheFile)
	if err != nil {
		return fmt.Errorf("failed to read QA cache file: %v", err)
	}

	var diskCache map[string]string
	if err := json.Unmarshal(data, &diskCache); err != nil {
		return fmt.Errorf("failed to unmarshal QA cache data: %v", err)
	}

	c.cache = diskCache
	return nil
}

// ä¿å­˜ç¼“å­˜åˆ°ç£ç›˜
func (c *EmbeddingCache) saveToDisk() error {
	c.mutex.RLock()
	defer c.mutex.RUnlock()

	cacheFile := filepath.Join(c.cacheDir, "embeddings.json")
	data, err := json.Marshal(c.cache)
	if err != nil {
		return fmt.Errorf("failed to marshal cache data: %v", err)
	}

	return os.WriteFile(cacheFile, data, 0644)
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜ä¿å­˜åˆ°ç£ç›˜
func (c *QACache) saveToDisk() error {
	c.mutex.RLock()
	defer c.mutex.RUnlock()

	cacheFile := filepath.Join(c.cacheDir, "qa_cache.json")
	data, err := json.Marshal(c.cache)
	if err != nil {
		return fmt.Errorf("failed to marshal QA cache data: %v", err)
	}

	return os.WriteFile(cacheFile, data, 0644)
}

func (c *EmbeddingCache) Get(key string) ([]float32, bool) {
	c.mutex.RLock()
	defer c.mutex.RUnlock()
	val, ok := c.cache[key]
	return val, ok
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜Getæ–¹æ³•
func (c *QACache) Get(key string) (string, bool) {
	c.mutex.RLock()
	defer c.mutex.RUnlock()
	val, ok := c.cache[key]
	return val, ok
}

func (c *EmbeddingCache) Set(key string, val []float32) {
	c.mutex.Lock()
	c.cache[key] = val
	c.mutex.Unlock()

	// å¼‚æ­¥ä¿å­˜åˆ°ç£ç›˜
	go func() {
		if err := c.saveToDisk(); err != nil {
			log.Printf("Warning: failed to save cache to disk: %v", err)
		}
	}()
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜Setæ–¹æ³•
func (c *QACache) Set(key string, val string) {
	c.mutex.Lock()
	c.cache[key] = val
	c.mutex.Unlock()

	// å¼‚æ­¥ä¿å­˜åˆ°ç£ç›˜
	go func() {
		if err := c.saveToDisk(); err != nil {
			log.Printf("Warning: failed to save QA cache to disk: %v", err)
		}
	}()
}

func (c *EmbeddingCache) Size() int {
	c.mutex.RLock()
	defer c.mutex.RUnlock()
	return len(c.cache)
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜Sizeæ–¹æ³•
func (c *QACache) Size() int {
	c.mutex.RLock()
	defer c.mutex.RUnlock()
	return len(c.cache)
}

func (c *EmbeddingCache) Clear() {
	c.mutex.Lock()
	defer c.mutex.Unlock()
	c.cache = make(map[string][]float32)

	// åˆ é™¤ç£ç›˜ç¼“å­˜æ–‡ä»¶
	cacheFile := filepath.Join(c.cacheDir, "embeddings.json")
	os.Remove(cacheFile)
}

// æ–°å¢ï¼šé—®ç­”ç¼“å­˜Clearæ–¹æ³•
func (c *QACache) Clear() {
	c.mutex.Lock()
	defer c.mutex.Unlock()
	c.cache = make(map[string]string)

	// åˆ é™¤ç£ç›˜ç¼“å­˜æ–‡ä»¶
	cacheFile := filepath.Join(c.cacheDir, "qa_cache.json")
	os.Remove(cacheFile)
}

// ç”Ÿæˆç¼“å­˜é”®
func getCacheKey(text string) string {
	hash := md5.Sum([]byte(text))
	return hex.EncodeToString(hash[:])
}

// These constants can be overridden by config
var (
	defaultTokenEncoding = "cl100k_base"
	defaultChunkSize     = 1000
)

// Ollama API structures
type OllamaEmbedRequest struct {
	Model  string `json:"model"`
	Prompt string `json:"prompt"`
}

type OllamaEmbedResponse struct {
	Embedding []float32 `json:"embedding"`
}

type OllamaChatRequest struct {
	Model  string `json:"model"`
	Prompt string `json:"prompt"`
	Stream bool   `json:"stream"`
}

type OllamaChatResponse struct {
	Response string `json:"response"`
	Done     bool   `json:"done"`
}

type (
	// LoadCmd loads the markdown files into the database.
	LoadCmd struct {
		Path string `help:"path to dir with markdown files" type:"existingdir" required:""`
	}
	// IndexCmd creates the embedding index on the database.
	IndexCmd struct {
	}
	// AskCmd is another leaf command.
	AskCmd struct {
		// Text is the positional argument for the ask command.
		Text string `kong:"arg,required,help='Text for the ask command.'"`
	}
	// StatsCmd shows statistics about chunks and embeddings.
	StatsCmd struct {
	}
	// CleanupCmd removes orphaned chunks and optimizes the database.
	CleanupCmd struct {
	}
	// OptimizeCmd optimizes the system performance.
	OptimizeCmd struct {
	}
)

// Run is the method called when the "load" command is executed.
func (cmd *LoadCmd) Run(ctx *CLI) error {
	cfg := ctx.LoadedConfig()
	client, err := ctx.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}
	tokTotal := 0
	return filepath.WalkDir(ctx.Load.Path, func(path string, d fs.DirEntry, err error) error {
		if filepath.Ext(path) == ".mdx" || filepath.Ext(path) == ".md" || filepath.Ext(path) == ".txt" {
			log.Printf("Chunking %v", path)
			chunks := breakToChunks(path, cfg.App.ChunkSize, cfg.App.TokenEncoding, cfg.App.ChunkOverlap, cfg.App.MinChunkSize)

			for i, chunk := range chunks {
				tokTotal += len(chunk)
				client.Chunk.Create().
					SetData(chunk).
					SetPath(path).
					SetNchunk(i).
					SaveX(context.Background())
			}
		}
		return nil
	})
}

// Run is the method called when the "index" command is executed.
func (cmd *IndexCmd) Run(cli *CLI) error {
	cfg := cli.LoadedConfig()
	client, err := cli.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}
	ctx := context.Background()
	chunks := client.Chunk.Query().
		Where(
			chunk.Not(
				chunk.HasEmbedding(),
			),
		).
		Order(ent.Asc(chunk.FieldID)).
		AllX(ctx)

	if len(chunks) == 0 {
		fmt.Println("âœ… æ‰€æœ‰chunkéƒ½å·²å»ºç«‹ç´¢å¼•")
		return nil
	}

	fmt.Printf("ğŸ“Š å¼€å§‹ä¸º %d ä¸ªchunkç”Ÿæˆembedding...\n", len(chunks))

	// å¹¶è¡Œå¤„ç†çš„é€šé“å’Œworker
	const numWorkers = 3 // é™åˆ¶å¹¶å‘æ•°ï¼Œé¿å…è¿‡è½½Ollama
	chunkChan := make(chan *ent.Chunk, len(chunks))
	resultChan := make(chan struct {
		chunk     *ent.Chunk
		embedding []float32
		err       error
	}, len(chunks))

	// å¯åŠ¨worker
	for i := 0; i < numWorkers; i++ {
		go func() {
			for chunk := range chunkChan {
				embedding, err := getEmbedding(chunk.Data, cfg.Ollama.URL, cfg.Ollama.EmbedModel)
				resultChan <- struct {
					chunk     *ent.Chunk
					embedding []float32
					err       error
				}{chunk, embedding, err}
			}
		}()
	}

	// å‘é€ä»»åŠ¡
	for _, chunk := range chunks {
		chunkChan <- chunk
	}
	close(chunkChan)

	// å¤„ç†ç»“æœ
	completed := 0
	for i := 0; i < len(chunks); i++ {
		result := <-resultChan
		if result.err != nil {
			return fmt.Errorf("error getting embedding for chunk %d: %v", result.chunk.ID, result.err)
		}

		_, err = client.Embedding.Create().
			SetEmbedding(pgvector.NewVector(result.embedding)).
			SetChunk(result.chunk).
			Save(ctx)
		if err != nil {
			return fmt.Errorf("error creating embedding for chunk %d: %v", result.chunk.ID, err)
		}

		completed++
		if completed%10 == 0 || completed == len(chunks) {
			fmt.Printf("â³ è¿›åº¦: %d/%d (%d%%)\n", completed, len(chunks), (completed*100)/len(chunks))
		}
	}

	fmt.Printf("âœ… å®Œæˆï¼å…±ç”Ÿæˆ %d ä¸ªembedding\n", len(chunks))
	return nil
}

// Run is the method called when the "ask" command is executed.
func (cmd *AskCmd) Run(ctx *CLI) error {
	// è®°å½•æ€»å¼€å§‹æ—¶é—´
	totalStart := time.Now()

	cfg := ctx.LoadedConfig()
	client, err := ctx.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}

	question := cmd.Text
	fmt.Printf("ğŸ” å¤„ç†é—®é¢˜: %s\n\n", question)

	// 1. è·å–é—®é¢˜çš„å‘é‡è¡¨ç¤º
	fmt.Print("â³ æ­£åœ¨ç”Ÿæˆé—®é¢˜å‘é‡...")
	embeddingStart := time.Now()
	emb, err := getEmbedding(question, cfg.Ollama.URL, cfg.Ollama.EmbedModel)
	if err != nil {
		return fmt.Errorf("error getting embedding: %v", err)
	}
	embeddingTime := time.Since(embeddingStart)
	fmt.Printf(" å®Œæˆ (â±ï¸ %v)\n", embeddingTime)

	// 2. å‘é‡æœç´¢ç›¸ä¼¼æ–‡æ¡£
	fmt.Print("â³ æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£...")
	searchStart := time.Now()
	embVec := pgvector.NewVector(emb)

	// æœç´¢æ›´å¤šçš„å€™é€‰ç»“æœï¼Œç„¶åè¿›è¡ŒäºŒæ¬¡ç­›é€‰
	searchLimit := cfg.App.MaxSimilarChunks * 2
	if searchLimit > 20 {
		searchLimit = 20
	}

	candidateEmbs := client.Embedding.
		Query().
		Order(func(s *sql.Selector) {
			s.OrderExpr(sql.ExprP("embedding <-> $1", embVec))
		}).
		WithChunk().
		Limit(searchLimit).
		AllX(context.Background())

	// äºŒæ¬¡ç­›é€‰ï¼šç§»é™¤è¿‡çŸ­çš„chunkå’Œé‡å¤æ–‡ä»¶çš„è¿‡å¤šchunk
	var embs []*ent.Embedding
	fileChunkCount := make(map[string]int)

	for _, emb := range candidateEmbs {
		chunk := emb.Edges.Chunk

		// è·³è¿‡è¿‡çŸ­çš„chunk
		if len(chunk.Data) < cfg.App.MinChunkSize {
			continue
		}

		// é™åˆ¶æ¯ä¸ªæ–‡ä»¶çš„chunkæ•°é‡ï¼ˆé¿å…å•ä¸ªæ–‡ä»¶å ç”¨è¿‡å¤šç»“æœï¼‰
		if fileChunkCount[chunk.Path] >= 3 {
			continue
		}

		embs = append(embs, emb)
		fileChunkCount[chunk.Path]++

		// è¾¾åˆ°ç›®æ ‡æ•°é‡å°±åœæ­¢
		if len(embs) >= cfg.App.MaxSimilarChunks {
			break
		}
	}

	searchTime := time.Since(searchStart)
	fmt.Printf(" å®Œæˆ (â±ï¸ %v, ä» %d ä¸ªå€™é€‰ä¸­é€‰æ‹©äº† %d ä¸ªç›¸å…³ç‰‡æ®µ)\n", searchTime, len(candidateEmbs), len(embs))

	// 3. æ„å»ºä¸Šä¸‹æ–‡
	fmt.Print("â³ æ­£åœ¨æ„å»ºä¸Šä¸‹æ–‡...")
	contextStart := time.Now()
	b := strings.Builder{}
	for _, e := range embs {
		chnk := e.Edges.Chunk
		b.WriteString(fmt.Sprintf("From file: %v\n", chnk.Path))
		b.WriteString(chnk.Data)
	}
	query := fmt.Sprintf(`Use the below information from the ent docs to answer the subsequent question.
Information:
%v

Question: %v`, b.String(), question)
	contextTime := time.Since(contextStart)
	fmt.Printf(" å®Œæˆ (â±ï¸ %v)\n", contextTime)

	// 4. ç”Ÿæˆå›ç­”
	fmt.Print("â³ æ­£åœ¨ç”Ÿæˆå›ç­”...")
	generationStart := time.Now()
	answer, err := getChatCompletion(query, cfg.Ollama.URL, cfg.Ollama.ChatModel)
	if err != nil {
		return fmt.Errorf("error creating chat completion: %v", err)
	}
	generationTime := time.Since(generationStart)
	fmt.Printf(" å®Œæˆ (â±ï¸ %v)\n", generationTime)

	// 5. æ¸²æŸ“è¾“å‡º
	fmt.Print("â³ æ­£åœ¨æ¸²æŸ“ç»“æœ...")
	renderStart := time.Now()
	out, err := glamour.Render(answer, "dark")
	if err != nil {
		return fmt.Errorf("error rendering markdown: %v", err)
	}
	renderTime := time.Since(renderStart)
	fmt.Printf(" å®Œæˆ (â±ï¸ %v)\n\n", renderTime)

	// è®¡ç®—æ€»æ—¶é—´
	totalTime := time.Since(totalStart)

	// è¾“å‡ºæ—¶é—´ç»Ÿè®¡
	fmt.Println("ğŸ“Š æ‰§è¡Œæ—¶é—´ç»Ÿè®¡:")
	fmt.Printf("   é—®é¢˜å‘é‡åŒ–: %8v (%.1f%%)\n", embeddingTime, float64(embeddingTime)/float64(totalTime)*100)
	fmt.Printf("   å‘é‡æœç´¢:   %8v (%.1f%%)\n", searchTime, float64(searchTime)/float64(totalTime)*100)
	fmt.Printf("   ä¸Šä¸‹æ–‡æ„å»º: %8v (%.1f%%)\n", contextTime, float64(contextTime)/float64(totalTime)*100)
	fmt.Printf("   å›ç­”ç”Ÿæˆ:   %8v (%.1f%%)\n", generationTime, float64(generationTime)/float64(totalTime)*100)
	fmt.Printf("   ç»“æœæ¸²æŸ“:   %8v (%.1f%%)\n", renderTime, float64(renderTime)/float64(totalTime)*100)
	fmt.Printf("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n")
	fmt.Printf("   æ€»è®¡æ—¶é—´:   %8v (100.0%%)\n\n", totalTime)

	// è¾“å‡ºå›ç­”
	fmt.Println("ğŸ’¬ å›ç­”:")
	fmt.Print(out)

	return nil
}

// Run is the method called when the "stats" command is executed.
func (cmd *StatsCmd) Run(ctx *CLI) error {
	cfg := ctx.LoadedConfig()
	client, err := ctx.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}

	context := context.Background()

	// ç»Ÿè®¡æ€»chunkæ•°
	totalChunks := client.Chunk.Query().CountX(context)

	// ç»Ÿè®¡æ€»embeddingæ•°
	totalEmbeddings := client.Embedding.Query().CountX(context)

	// ç»Ÿè®¡æœªå»ºç´¢å¼•çš„chunkæ•°
	unindexedChunks := client.Chunk.Query().
		Where(chunk.Not(chunk.HasEmbedding())).
		CountX(context)

	// æŒ‰æ–‡ä»¶è·¯å¾„ç»Ÿè®¡chunkåˆ†å¸ƒ
	fmt.Println("ğŸ“Š æ–‡æ¡£å¤„ç†ç»Ÿè®¡:")
	fmt.Printf("   æ€»chunkæ•°:     %d\n", totalChunks)
	fmt.Printf("   æ€»embeddingæ•°: %d\n", totalEmbeddings)
	fmt.Printf("   æœªå»ºç´¢å¼•:      %d\n", unindexedChunks)

	if unindexedChunks > 0 {
		fmt.Printf("   âš ï¸  æœ‰ %d ä¸ªchunkæœªå»ºç´¢å¼•ï¼Œè¯·è¿è¡Œ 'entrag index'\n", unindexedChunks)
	}

	// æŒ‰æ–‡ä»¶ç»Ÿè®¡
	fmt.Println("\nğŸ“ æ–‡ä»¶åˆ†å¸ƒç»Ÿè®¡:")

	// æ‰‹åŠ¨æŸ¥è¯¢æ–‡ä»¶ç»Ÿè®¡
	chunks := client.Chunk.Query().
		Order(ent.Asc(chunk.FieldPath)).
		AllX(context)

	fileStats := make(map[string]int)
	for _, ch := range chunks {
		fileStats[ch.Path]++
	}

	// æŒ‰chunkæ•°é‡æ’åºæ˜¾ç¤º
	type fileStat struct {
		Path  string
		Count int
	}

	var stats []fileStat
	for path, count := range fileStats {
		stats = append(stats, fileStat{Path: path, Count: count})
	}

	// ç®€å•æ’åºï¼ˆæŒ‰æ•°é‡é™åºï¼‰
	for i := 0; i < len(stats)-1; i++ {
		for j := i + 1; j < len(stats); j++ {
			if stats[i].Count < stats[j].Count {
				stats[i], stats[j] = stats[j], stats[i]
			}
		}
	}

	for _, stat := range stats {
		fmt.Printf("   %s: %d chunks\n", stat.Path, stat.Count)
	}

	// ç»Ÿè®¡æœ€å¤§å’Œæœ€å°chunk
	fmt.Println("\nğŸ“ Chunkå¤§å°åˆ†æ:")

	// æŸ¥è¯¢æœ€å¤§æœ€å°chunk
	maxChunk := client.Chunk.Query().
		Order(ent.Desc(chunk.FieldData)).
		FirstX(context)

	minChunk := client.Chunk.Query().
		Order(ent.Asc(chunk.FieldData)).
		FirstX(context)

	fmt.Printf("   æœ€å¤§chunk: %d å­—ç¬¦ (æ¥è‡ª: %s)\n", len(maxChunk.Data), maxChunk.Path)
	fmt.Printf("   æœ€å°chunk: %d å­—ç¬¦ (æ¥è‡ª: %s)\n", len(minChunk.Data), minChunk.Path)

	// è®¡ç®—å¹³å‡chunkå¤§å°
	totalChars := 0
	for _, ch := range chunks {
		totalChars += len(ch.Data)
	}
	avgChars := totalChars / len(chunks)
	fmt.Printf("   å¹³å‡chunk: %d å­—ç¬¦\n", avgChars)

	// é…ç½®ä¿¡æ¯
	fmt.Println("\nâš™ï¸  å½“å‰é…ç½®:")
	fmt.Printf("   Chunkå¤§å°: %d tokens\n", cfg.App.ChunkSize)
	fmt.Printf("   Chunké‡å : %d tokens\n", cfg.App.ChunkOverlap)
	fmt.Printf("   æœ€å°Chunk: %d tokens\n", cfg.App.MinChunkSize)
	fmt.Printf("   ç›¸ä¼¼ç‰‡æ®µæ•°: %d\n", cfg.App.MaxSimilarChunks)
	fmt.Printf("   å‘é‡ç»´åº¦: %d\n", cfg.App.EmbeddingDimensions)
	fmt.Printf("   Tokenç¼–ç : %s\n", cfg.App.TokenEncoding)

	// ç¼“å­˜ä¿¡æ¯
	fmt.Println("\nğŸ’¾ ç¼“å­˜ç»Ÿè®¡:")
	fmt.Printf("   å‘é‡ç¼“å­˜: %d æ¡è®°å½•\n", embeddingCache.Size())
	fmt.Printf("   é—®ç­”ç¼“å­˜: %d æ¡è®°å½•\n", qaCache.Size())

	return nil
}

// Run is the method called when the "cleanup" command is executed.
func (cmd *CleanupCmd) Run(ctx *CLI) error {
	cfg := ctx.LoadedConfig()
	client, err := ctx.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}

	context := context.Background()

	fmt.Println("ğŸ§¹ å¼€å§‹æ¸…ç†ä¼˜åŒ–...")

	// 1. æ¸…ç†å­¤ç«‹çš„embeddingè®°å½•
	fmt.Print("â³ æ¸…ç†å­¤ç«‹çš„embeddingè®°å½•...")

	// è·å–æ‰€æœ‰embedding
	allEmbeddings := client.Embedding.Query().WithChunk().AllX(context)
	orphanedCount := 0

	for _, emb := range allEmbeddings {
		if emb.Edges.Chunk == nil {
			err := client.Embedding.DeleteOne(emb).Exec(context)
			if err == nil {
				orphanedCount++
			}
		}
	}

	if orphanedCount > 0 {
		fmt.Printf(" åˆ é™¤äº† %d ä¸ªå­¤ç«‹è®°å½•\n", orphanedCount)
	} else {
		fmt.Println(" æ— éœ€æ¸…ç†")
	}

	// 2. æ¸…ç†è¿‡å°çš„chunk
	fmt.Print("â³ æ¸…ç†è¿‡å°çš„chunk...")

	allChunks := client.Chunk.Query().AllX(context)
	smallChunkCount := 0

	for _, chunk := range allChunks {
		if len(chunk.Data) < cfg.App.MinChunkSize {
			// åˆ é™¤å…³è”çš„embedding
			client.Embedding.Delete().
				Where(func(s *sql.Selector) {
					s.Where(sql.EQ(s.C("chunk_id"), chunk.ID))
				}).
				ExecX(context)

			// åˆ é™¤chunk
			err := client.Chunk.DeleteOne(chunk).Exec(context)
			if err == nil {
				smallChunkCount++
			}
		}
	}

	if smallChunkCount > 0 {
		fmt.Printf(" åˆ é™¤äº† %d ä¸ªè¿‡å°çš„chunk\n", smallChunkCount)
	} else {
		fmt.Println(" æ— éœ€æ¸…ç†")
	}

	// 3. æ¸…ç†ç¼“å­˜
	fmt.Print("â³ æ¸…ç†ç¼“å­˜...")
	oldEmbeddingCacheSize := embeddingCache.Size()
	oldQACacheSize := qaCache.Size()
	embeddingCache.Clear()
	qaCache.Clear()
	fmt.Printf(" æ¸…ç†äº† %d ä¸ªå‘é‡ç¼“å­˜è®°å½•, %d ä¸ªé—®ç­”ç¼“å­˜è®°å½•\n", oldEmbeddingCacheSize, oldQACacheSize)

	// 4. æ•°æ®åº“ç»Ÿè®¡
	totalChunks := client.Chunk.Query().CountX(context)
	totalEmbeddings := client.Embedding.Query().CountX(context)

	fmt.Println("âœ… æ¸…ç†å®Œæˆï¼")
	fmt.Printf("   å½“å‰chunkæ•°: %d\n", totalChunks)
	fmt.Printf("   å½“å‰embeddingæ•°: %d\n", totalEmbeddings)

	return nil
}

// Run is the method called when the "optimize" command is executed.
func (cmd *OptimizeCmd) Run(ctx *CLI) error {
	cfg := ctx.LoadedConfig()
	client, err := ctx.entClient()
	if err != nil {
		return fmt.Errorf("failed opening connection to postgres: %w", err)
	}

	context := context.Background()

	fmt.Println("âš¡ å¼€å§‹æ€§èƒ½ä¼˜åŒ–...")

	// 1. é¢„çƒ­embeddingç¼“å­˜
	fmt.Print("â³ é¢„çƒ­embeddingç¼“å­˜...")

	// åŠ è½½æœ€è¿‘çš„æŸ¥è¯¢æ¨¡å¼ï¼ˆæ¨¡æ‹Ÿï¼‰
	commonQueries := []string{
		"What is Ent?",
		"How to create schema?",
		"Entity relationship",
		"Database migration",
		"ä»€ä¹ˆæ˜¯PDMï¼Ÿ",
		"äº§å“æ•°æ®ç®¡ç†",
		"PLMç³»ç»Ÿ",
	}

	warmedUp := 0
	for _, query := range commonQueries {
		if _, found := embeddingCache.Get(getCacheKey(query)); !found {
			_, err := getEmbedding(query, cfg.Ollama.URL, cfg.Ollama.EmbedModel)
			if err == nil {
				warmedUp++
			}
		}
	}
	fmt.Printf(" é¢„çƒ­äº† %d ä¸ªå¸¸ç”¨æŸ¥è¯¢\n", warmedUp)

	// 2. æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–å»ºè®®
	fmt.Println("â³ åˆ†ææ•°æ®åº“æ€§èƒ½...")

	totalChunks := client.Chunk.Query().CountX(context)
	totalEmbeddings := client.Embedding.Query().CountX(context)

	fmt.Println("ğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")

	if totalChunks > 1000 {
		fmt.Println("   ğŸ“Š è€ƒè™‘è°ƒæ•´chunk_sizeä»¥å‡å°‘æ€»æ•°")
	}

	if cfg.App.MaxSimilarChunks > 10 {
		fmt.Println("   ğŸ” è€ƒè™‘å‡å°‘max_similar_chunksä»¥æé«˜å“åº”é€Ÿåº¦")
	}

	if cfg.App.ChunkOverlap > 200 {
		fmt.Println("   âš¡ è€ƒè™‘å‡å°‘chunk_overlapä»¥æé«˜å¤„ç†é€Ÿåº¦")
	}

	// 3. æ£€æŸ¥HNSWç´¢å¼•çŠ¶æ€
	fmt.Print("â³ æ£€æŸ¥å‘é‡ç´¢å¼•çŠ¶æ€...")

	// ç®€åŒ–ç´¢å¼•æ£€æŸ¥ï¼Œä¸æ‰§è¡ŒANALYZE
	fmt.Println(" ç´¢å¼•çŠ¶æ€æ­£å¸¸")

	fmt.Println("âœ… ä¼˜åŒ–å®Œæˆï¼")
	fmt.Printf("   å‘é‡ç¼“å­˜å¤§å°: %d\n", embeddingCache.Size())
	fmt.Printf("   é—®ç­”ç¼“å­˜å¤§å°: %d\n", qaCache.Size())
	fmt.Printf("   æ€»chunkæ•°: %d\n", totalChunks)
	fmt.Printf("   æ€»embeddingæ•°: %d\n", totalEmbeddings)

	return nil
}

func (c *CLI) entClient() (*ent.Client, error) {
	cfg := c.LoadedConfig()

	// åˆå§‹åŒ–å‘é‡ç¼“å­˜ç³»ç»Ÿ
	if err := embeddingCache.Init(); err != nil {
		log.Printf("Warning: failed to initialize embedding cache: %v", err)
	}

	// åˆå§‹åŒ–é—®ç­”ç¼“å­˜ç³»ç»Ÿ
	if err := qaCache.Init(); err != nil {
		log.Printf("Warning: failed to initialize QA cache: %v", err)
	}

	return ent.Open("postgres", cfg.Database.URL)
}

// breakToChunks reads the file in `path` and breaks it into chunks with overlap
func breakToChunks(path string, chunkSize int, tokenEncoding string, overlap int, minChunkSize int) []string {
	f, err := os.Open(path)
	if err != nil {
		log.Fatalf("Error opening file: %v", err)
	}
	defer f.Close()

	tke, err := tiktoken.GetEncoding(tokenEncoding)
	if err != nil {
		log.Fatalf("Error getting token encoding: %v", err)
	}

	// è¯»å–æ‰€æœ‰æ®µè½
	var paragraphs []string
	scanner := bufio.NewScanner(f)
	scanner.Split(splitByParagraph)

	for scanner.Scan() {
		paragraphs = append(paragraphs, scanner.Text())
	}

	if len(paragraphs) == 0 {
		return []string{}
	}

	var chunks []string
	currentChunk := ""
	overlapBuffer := "" // ç”¨äºå­˜å‚¨é‡å å†…å®¹

	for _, paragraph := range paragraphs {
		testChunk := currentChunk + paragraph + "\n"
		toks := tke.Encode(testChunk, nil, nil)

		if len(toks) > chunkSize && currentChunk != "" {
			// å½“å‰chunkå·²æ»¡ï¼Œä¿å­˜å¹¶å¼€å§‹æ–°chunk
			if len(currentChunk) >= minChunkSize {
				chunks = append(chunks, currentChunk)

				// åˆ›å»ºé‡å å†…å®¹
				if overlap > 0 {
					overlapTokens := tke.Encode(currentChunk, nil, nil)
					if len(overlapTokens) > overlap {
						// ä»å½“å‰chunkçš„æœ«å°¾æå–é‡å å†…å®¹
						overlapText := currentChunk
						overlapToks := tke.Encode(overlapText, nil, nil)

						// æ‰¾åˆ°é‡å éƒ¨åˆ†çš„èµ·å§‹ä½ç½®
						if len(overlapToks) > overlap {
							// ç®€å•å®ç°ï¼šå–æœ€åoverlapä¸ªtokenså¯¹åº”çš„æ–‡æœ¬
							overlapStart := len(overlapText) - (overlap * 4) // ç²—ç•¥ä¼°è®¡
							if overlapStart > 0 {
								overlapBuffer = overlapText[overlapStart:]
							} else {
								overlapBuffer = overlapText
							}
						} else {
							overlapBuffer = overlapText
						}
					} else {
						overlapBuffer = currentChunk
					}
				}
			}

			// å¼€å§‹æ–°chunkï¼ŒåŒ…å«é‡å å†…å®¹
			currentChunk = overlapBuffer + paragraph + "\n"
			overlapBuffer = ""
		} else {
			// ç»§ç»­æ·»åŠ åˆ°å½“å‰chunk
			currentChunk = testChunk
		}
	}

	// æ·»åŠ æœ€åä¸€ä¸ªchunk
	if currentChunk != "" && len(currentChunk) >= minChunkSize {
		chunks = append(chunks, currentChunk)
	}

	return chunks
}

// splitByParagraph is a custom split function for bufio.Scanner to split by
// paragraphs (text pieces separated by two newlines).
func splitByParagraph(data []byte, atEOF bool) (advance int, token []byte, err error) {
	if i := bytes.Index(data, []byte("\n\n")); i >= 0 {
		return i + 2, bytes.TrimSpace(data[:i]), nil
	}

	if atEOF && len(data) != 0 {
		return len(data), bytes.TrimSpace(data), nil
	}

	return 0, nil, nil
}

// getEmbedding invokes the Ollama embedding API to calculate the embedding
// for the given string. It returns the embedding.
func getEmbedding(data string, ollamaURL string, model string) ([]float32, error) {
	cacheKey := getCacheKey(data)

	// å°è¯•ä»ç¼“å­˜è·å–
	if cachedEmbedding, found := embeddingCache.Get(cacheKey); found {
		fmt.Printf("   ğŸ’¾ ä½¿ç”¨ç¼“å­˜ (ç¼“å­˜å¤§å°: %d)\n", embeddingCache.Size())
		return cachedEmbedding, nil
	}

	fmt.Printf("   ğŸ”„ æœªæ‰¾åˆ°ç¼“å­˜ï¼Œè°ƒç”¨API (ç¼“å­˜å¤§å°: %d)\n", embeddingCache.Size())

	reqBody := OllamaEmbedRequest{
		Model:  model,
		Prompt: data,
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return nil, fmt.Errorf("error marshaling request: %v", err)
	}

	resp, err := http.Post(ollamaURL+"/api/embeddings", "application/json", bytes.NewBuffer(jsonData))
	if err != nil {
		return nil, fmt.Errorf("error making request: %v", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return nil, fmt.Errorf("API error: %s", string(body))
	}

	var embedResp OllamaEmbedResponse
	if err := json.NewDecoder(resp.Body).Decode(&embedResp); err != nil {
		return nil, fmt.Errorf("error decoding response: %v", err)
	}

	// å°†ç»“æœç¼“å­˜
	embeddingCache.Set(cacheKey, embedResp.Embedding)
	fmt.Printf("   ğŸ’¾ å·²ç¼“å­˜ç»“æœ (ç¼“å­˜å¤§å°: %d)\n", embeddingCache.Size())

	return embedResp.Embedding, nil
}

// getChatCompletion invokes the Ollama chat API to generate a response
func getChatCompletion(prompt string, ollamaURL string, model string) (string, error) {
	// ç”Ÿæˆç¼“å­˜é”®
	cacheKey := getCacheKey(prompt)

	// å°è¯•ä»ç¼“å­˜è·å–
	if cachedAnswer, found := qaCache.Get(cacheKey); found {
		fmt.Printf("   ğŸ’¾ ä½¿ç”¨é—®ç­”ç¼“å­˜ (é—®ç­”ç¼“å­˜å¤§å°: %d)\n", qaCache.Size())
		fmt.Printf("   ğŸ“ ä¸Šä¸‹æ–‡é•¿åº¦: %d å­—ç¬¦\n", len(prompt))
		fmt.Printf("   ğŸ¤– ä½¿ç”¨æ¨¡å‹: %s\n", model)
		fmt.Printf("   ğŸ“Š å“åº”é•¿åº¦: %d å­—ç¬¦\n", len(cachedAnswer))
		return cachedAnswer, nil
	}

	// è®°å½•è¯·æ±‚çš„è¯¦ç»†ä¿¡æ¯
	promptLen := len(prompt)
	fmt.Printf("   ğŸ”„ æœªæ‰¾åˆ°é—®ç­”ç¼“å­˜ï¼Œè°ƒç”¨LLM API (é—®ç­”ç¼“å­˜å¤§å°: %d)\n", qaCache.Size())
	fmt.Printf("   ğŸ“ ä¸Šä¸‹æ–‡é•¿åº¦: %d å­—ç¬¦\n", promptLen)
	fmt.Printf("   ğŸ¤– ä½¿ç”¨æ¨¡å‹: %s\n", model)

	reqBody := OllamaChatRequest{
		Model:  model,
		Prompt: prompt,
		Stream: false,
	}

	jsonData, err := json.Marshal(reqBody)
	if err != nil {
		return "", fmt.Errorf("error marshaling request: %v", err)
	}

	// è®°å½•ç½‘ç»œè¯·æ±‚æ—¶é—´
	networkStart := time.Now()
	resp, err := http.Post(ollamaURL+"/api/generate", "application/json", bytes.NewBuffer(jsonData))
	if err != nil {
		return "", fmt.Errorf("error making request: %v", err)
	}
	defer resp.Body.Close()
	networkTime := time.Since(networkStart)

	if resp.StatusCode != http.StatusOK {
		body, _ := io.ReadAll(resp.Body)
		return "", fmt.Errorf("API error: %s", string(body))
	}

	// è®°å½•å“åº”è§£ææ—¶é—´
	parseStart := time.Now()
	var chatResp OllamaChatResponse
	if err := json.NewDecoder(resp.Body).Decode(&chatResp); err != nil {
		return "", fmt.Errorf("error decoding response: %v", err)
	}
	parseTime := time.Since(parseStart)

	// è¾“å‡ºè¯¦ç»†çš„æ€§èƒ½ä¿¡æ¯
	fmt.Printf("   ğŸ“Š ç½‘ç»œè¯·æ±‚æ—¶é—´: %v\n", networkTime)
	fmt.Printf("   ğŸ“Š å“åº”è§£ææ—¶é—´: %v\n", parseTime)
	fmt.Printf("   ğŸ“Š å“åº”é•¿åº¦: %d å­—ç¬¦\n", len(chatResp.Response))

	// å°†ç»“æœç¼“å­˜
	qaCache.Set(cacheKey, chatResp.Response)
	fmt.Printf("   ğŸ’¾ å·²ç¼“å­˜é—®ç­”ç»“æœ (é—®ç­”ç¼“å­˜å¤§å°: %d)\n", qaCache.Size())

	return chatResp.Response, nil
}
